[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Short Stories on Machine Learning\n",
    "section": "",
    "text": "These pages are a collection of notes I’ve written mostly for my own sake to help me remember subtle arguments or how to think about concepts that constantly confuse me. In the hopes that maybe my way of thinking resonates with others, I’ve decided to share these notes here.\nPlease feel free to reach out if you want to connect on these topics."
  },
  {
    "objectID": "blog/regularization.html",
    "href": "blog/regularization.html",
    "title": "Regularization as a Feature Selection Method",
    "section": "",
    "text": "Often thought of as a method to prevent overfitting, regularization can also be used to select the most important features from a model, as demonstrated in this post."
  },
  {
    "objectID": "blog/regularization.html#what-is-regularization",
    "href": "blog/regularization.html#what-is-regularization",
    "title": "Regularization as a Feature Selection Method",
    "section": "What is regularization?",
    "text": "What is regularization?\nIn any machine learning setting, you invariably find yourself with a set of parameters \\(\\vec{\\beta}\\), which you wish to estimate from the data \\(\\mathcal{D}\\). A standard approach to estimating \\(\\vec{\\beta}\\) is to write down a likelihood function \\(P(\\mathcal{D}|\\mathbf{\\beta})\\) and maximize the likelihood with respect to \\(\\vec{\\beta}\\). This approach is called maximum likelihood estimation.\nWith regularization, we shift from a maximum likelihood estimation to a maximum a posterior estimation. In the Bayes’ formulation, we have the posterior equation:\n\\[ P(\\vec{\\beta} | \\mathcal{D}) = \\frac{P(\\mathcal{D}|\\vec{\\beta}) P(\\vec{\\beta})}{P(\\mathcal{D})}, \\]\nwhere the term \\(P(\\vec{\\beta})\\) is called the prior. It represents all pre-existing information obtained about \\(\\vec{\\beta}\\), either through intuition or previous measurements. The term \\(P(\\mathcal{D}|\\mathbf{\\beta})\\) is the likelihood; for fixed \\(\\mathcal{D}\\), let’s denote the likelihood as \\(L(\\vec{\\beta})\\).\nTo find the peak of the posterior distribution (i.e. the maximum a posteriori estimate for \\(\\vec{\\beta}\\)), it is equivalent to minimize the following loss function:\n\\[ \\text{loss} = -\\log L(\\vec{\\beta}) - \\log P(\\vec{\\beta}). \\]\nWe can ignore the \\(P(\\mathcal{D})\\) term because it is constant with respect to \\(\\vec{\\beta}\\). If we take a constant prior, \\(P(\\vec{\\beta}) = 1\\), then the second term on the right hand side can be ignored and we have the standard maximum likelihood approach.\nHowever, there are very good reasons to enforce a non-constant prior on your parameters. For one, we almost always have useful prior knowledge. Consider a simple linear model \\(y \\sim \\vec{\\beta}\\cdot \\vec{x}\\). A standard first step in such an inference problem is to transform \\(\\vec{x}\\) and \\(y\\) such that they have zero mean and unit variance. If we do that, then we can already with fairly high confidence rule out large regions of parameter space. For instance, taking \\(\\beta_i = 100\\) would mean that a unit change in \\(x_i\\) would increase \\(y\\) by 100 standard deviations. This behavior seems unlikely in almost any setting.\nWe can encode this belief in a prior. The prior tells the model to avoid considering regions of parameter space with \\(|\\beta_i| \\sim 100\\), unless there is overwhelming evidence from the data (encoded in the likelihood). This can prevent you from falling into the trap of “overfitting” a model, i.e., seeing a pattern in the data that isn’t really there. The model may say “hey you know if I set \\(\\beta_2 = 100\\), I can explain pretty much everything in the data.” But the prior comes in and says “this conflicts with my expectations, I need more evidence of that before I can believe you.”\nThe devil is, as always, in the details. There are multiple ways to encode the preference for smaller parameters mathematically and which approach you choose turns out to make a big difference in the kind of solutions you obtain. Here, I want to explore two different choices of prior beliefs, both consistent with the preference for smaller parameters, and illustrate how these choices impact the inferred model parameters."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nRegularization as a Feature Selection Method\n\n\n\n\n\n\n\nmachine learning\n\n\nlogistic regression\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]