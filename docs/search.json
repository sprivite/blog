[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Short Stories on Machine Learning\n",
    "section": "",
    "text": "These pages are a collection of notes I’ve written mostly for my own sake to help me remember subtle arguments or how to think about concepts that constantly confuse me. I figure no one is more qualified to explain things to my future self than my past self. In the hopes that maybe my way of thinking resonates with others, I’ve decided to share these notes here.\nPlease feel free to reach out if you want to connect on these topics."
  },
  {
    "objectID": "blog/regularization.html",
    "href": "blog/regularization.html",
    "title": "Regularization in Machine Learning",
    "section": "",
    "text": "We discuss regularization in machine learning and illustrate its impact in a simple toy example using logistic regression."
  },
  {
    "objectID": "blog/regularization.html#what-is-regularization",
    "href": "blog/regularization.html#what-is-regularization",
    "title": "Regularization in Machine Learning",
    "section": "What is regularization?",
    "text": "What is regularization?\nIn any machine learning setting, you invariably find yourself with a set of parameters \\(\\vec{\\beta}\\), which you wish to estimate from the data \\(\\mathcal{D}\\). A standard approach to estimating \\(\\vec{\\beta}\\) is to write down a likelihood function \\(P(\\mathcal{D}|\\mathbf{\\beta})\\) and maximize the likelihood with respect to \\(\\vec{\\beta}\\). This approach is called maximum likelihood estimation.\nWith regularization, we shift from a maximum likelihood estimation to a maximum a posterior estimation. In the Bayes’ formulation, we have the posterior equation:\n\\[ P(\\vec{\\beta} | \\mathcal{D}) = \\frac{P(\\mathcal{D}|\\vec{\\beta}) P(\\vec{\\beta})}{P(\\mathcal{D})}, \\]\nwhere the term \\(P(\\vec{\\beta})\\) is called the prior. It represents all pre-existing information obtained about \\(\\vec{\\beta}\\), either through intuition or previous measurements. The term \\(P(\\mathcal{D}|\\mathbf{\\beta})\\) is the likelihood; for fixed \\(\\mathcal{D}\\), let’s denote the likelihood as \\(L(\\vec{\\beta})\\).\nTo find the peak of the posterior distribution (i.e. the maximum a posteriori estimate for \\(\\vec{\\beta}\\)), it is equivalent to minimize the following loss function:\n\\[ \\text{loss} = -\\log L(\\vec{\\beta}) - \\log P(\\vec{\\beta}). \\]\nWe can ignore the \\(P(\\mathcal{D})\\) term because it is constant with respect to \\(\\vec{\\beta}\\). If we take a constant prior, \\(P(\\vec{\\beta}) = 1\\), then the second term on the right hand side can be ignored and we have the standard maximum likelihood approach.\nHowever, there are very good reasons to enforce a prior on your parameters. Consider a simple linear model \\(y \\sim \\beta x\\). In many cases, we have very natural, if only loose bounds on \\(x\\) and \\(y\\) and these translate into bounds on \\(\\beta\\). For instance, if \\(x\\) is the population in a given geographic region and \\(y\\) is the annual number of fatal car accidents in that region, then probably neither is significantly larger that \\(10^9\\), since that’s the entire global population. So there’s an easy, loose, justifiable bound.\nIn that case, do you really believe that increasing \\(x\\) by one should ever increase \\(y\\) by \\(10^9\\)? The answer is “no”. And if not, then you shouldn’t even consider the region of parameter space with \\(\\beta \\sim 10^9\\), unless there is overwhelming evidence from the data (encoded in the likelihood). A prior does this for you naturally. It applies a sort of Occam’s razor to your analysis; given no evidence to the contrary, prefer smaller parameters.\nA more practical reason to include a prior is that, as the name of the method suggests, it regularizes the problem, i.e., it takes a problem that might be underconstrained and breaks symmetries in such a way as to usually guarantee a solution. As long as your prior goes to 0 faster that your likelihood grows as \\(\\beta \\to \\infty\\), you have essentially bounded your parameter space and a continuous function on a bounded region of space always has an absolute maximum.\nSo, always use a prior."
  },
  {
    "objectID": "blog/regularization.html#logistic-regression",
    "href": "blog/regularization.html#logistic-regression",
    "title": "Regularization in Machine Learning",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo see how L1 regularization impacts parameter estimation, let’s experiment with a toy classification problem using logistic regression. We simulate a dataset with 100 features, only 20 of which are informative. The remaining 80 are just noise. In the figure below, I’ve shown just four of the 100 variables, two informative and two non-informative.\n\n\nCode\nfrom sklearn.datasets import make_classification\n\nn_samples = 10000\nn_features = 100\nX, y = make_classification(\n    n_samples, \n    n_features, \n    n_informative=20, \n    n_redundant=0, \n    n_repeated=0, \n    n_classes=2,\n    class_sep=1,\n    shuffle=False,\n    random_state=123)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n\n\n\n\n\n\nFigure 1: One dimensional marginal distributions for a few varaibles in the simulation.\n\n\n\n\nNow let’s see what happens when we train a logistic regression with three different kinds of regularization terms: (1) no regularization, (2) L1 and (3) L2.\n\n\nCode\nfrom sklearn.linear_model import LogisticRegression\n\nclf_nopenalty = LogisticRegression(\n    penalty=None, \n    max_iter=10000, \n    solver='saga')\n\nclf_l1 = LogisticRegression(\n    penalty='l1', \n    max_iter=10000, \n    solver='saga', \n    C=0.01)\n\nclf_l2 = LogisticRegression(\n    penalty='l2', \n    max_iter=10000,\n    solver='saga', \n    C=0.001)\n\n\nWe want to show the L1 regularization can pick out the informative features. Before we do that, though, let’s take a look at the performance of the three models from the perspective of their predictive strength. Below, I show the ROC curve for each classifier on the hold-out test set. What we see is that three classifiers are indistinguishable in terms of their predictive capability. This might tempt you to think that regularization doesn’t matter for your problem. But that is wrong!\n\n\n\n\n\nFigure 2: ROC for each of three classifiers trained with different regularization options.\n\n\n\n\nThe classifiers look very different when we look at the resulting coefficients! Compared to no regularization, the L2 regularized classifiers returns all-around smaller coefficients. But the L1 regularized classifier does something even more remarkable. It returns exactly 19 non-zero coefficients! It was able to detect and remove most of the noise from the problem.\n\n\n\n\n\nFigure 3: Returned coefficients for each of the three classifiers. By the problem setup, only the first 20 parameters are expected to contribute to the signal. Only the L1 regularized model is able to learn that information.\n\n\n\n\nI’ve cheated here a little bit, however. I knew I wanted 20 parameters and so I picked a regularization coefficient (above called \\(\\alpha\\)) to give me roughly the right number of non-zero coefficients. How could we figure out the right regularization strength in practice?\nOne idea is to try a number of different regularization strengths. For each regularization strength, train a model and compute an out-of-sample metric (e.g. AUC). Then make a curve showing out-of-sample performance versus the number of non-zero coefficients, as shown below. The plot seems to suggest that using fewer than 20 features is detrimental to performance and that using significantly more than 20 does not help very much. Thus, we are able to extract, more or less, the correct number of features to use in our model.\n\n\n\n\n\nFigure 4: Performance versus number of features in model"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nRegularization in Machine Learning\n\n\n\n\n\n\n\nmachine learning\n\n\nlogistic regression\n\n\n\n\n\n\n\n\n\n\n\nMay 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]